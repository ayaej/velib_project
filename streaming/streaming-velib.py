"""
Pipeline Spark Structured Streaming pour r√©cup√©rer les donn√©es V√©lib en temps r√©el
R√©cup√®re l'API JCDecaux officielle, transforme les donn√©es et les ins√®re dans MongoDB
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
import requests
import json
import time
import os
import traceback
from datetime import datetime
from pymongo import MongoClient

# Configuration de l'API JCDecaux
JCDECAUX_API_KEY = os.getenv('JCDECAUX_API_KEY', 'YOUR_API_KEY_HERE')  # TODO: Remplacer par votre cl√© API
JCDECAUX_API_URL = f"https://api.jcdecaux.com/vls/v3/stations?apiKey={JCDECAUX_API_KEY}"
# Alternative pour Paris uniquement:
# JCDECAUX_API_URL = f"https://api.jcdecaux.com/vls/v3/stations?contract=paris&apiKey={JCDECAUX_API_KEY}"

# Configuration MongoDB
MONGODB_URI = "mongodb://admin:admin123@mongo:27017/"
MONGODB_DB = "velib_db"
MONGODB_COLLECTION = "stations"

# Configuration HDFS (optionnel pour archivage)
HDFS_ENABLED = os.getenv('HDFS_ENABLED', 'false').lower() == 'true'
HDFS_BASE_PATH = "hdfs://namenode:9000/velib/raw/"


def initialize_spark():
    """
    Initialiser la session Spark avec les configurations n√©cessaires
    """
    builder = SparkSession.builder \
        .appName("VelibRealtimeStreaming_JCDecaux") \
        .config("spark.mongodb.output.uri", f"{MONGODB_URI}{MONGODB_DB}.{MONGODB_COLLECTION}") \
        .config("spark.jars.packages", "org.mongodb.spark:mongo-spark-connector_2.12:10.2.0")
    
    if HDFS_ENABLED:
        builder = builder.config("spark.hadoop.fs.defaultFS", "hdfs://namenode:9000")
    
    spark = builder.getOrCreate()
    spark.sparkContext.setLogLevel("WARN")
    
    print("‚úÖ Spark session initialized")
    print(f"üì° API Source: JCDecaux V√©lib API")
    print(f"üíæ HDFS Archiving: {'Enabled' if HDFS_ENABLED else 'Disabled'}")
    
    return spark


def fetch_velib_data():
    """
    R√©cup√©rer les donn√©es de l'API JCDecaux en temps r√©el
    """
    try:
        print(f"üì° Fetching data from JCDecaux API...")
        
        response = requests.get(JCDECAUX_API_URL, timeout=15)
        response.raise_for_status()
        
        data = response.json()
        
        if isinstance(data, list):
            print(f"‚úÖ Fetched {len(data)} stations from JCDecaux API")
            return data
        else:
            print(f"‚ö†Ô∏è Unexpected response format")
            return []
            
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error fetching JCDecaux data: {e}")
        if "401" in str(e):
            print("‚ö†Ô∏è API Key invalide ou manquante!")
            print("üëâ Obtenez votre cl√© API gratuite sur: https://developer.jcdecaux.com")
        return []
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        return []


def transform_jcdecaux_record(record):
    """
    Transformer un enregistrement de l'API JCDecaux
    Structure de l'API JCDecaux:
    {
        "number": 16107,
        "contractName": "Paris",
        "name": "16107 - BENJAMIN GODARD - VICTOR HUGO",
        "address": "2 RUE BENJAMIN GODARD - 75016 PARIS",
        "position": {"latitude": 48.865983, "longitude": 2.275725},
        "banking": true,
        "bonus": false,
        "status": "OPEN",
        "lastUpdate": "2024-01-15T14:29:45.000Z",
        "connected": true,
        "overflow": false,
        "shape": null,
        "totalStands": {"availabilities": {...}, "capacity": 35},
        "mainStands": {"availabilities": {...}, "capacity": 35},
        "overflowStands": null
    }
    """
    try:
        # Extraction des donn√©es de base
        number = record.get('number', '')
        name = record.get('name', '')
        contract = record.get('contractName', 'Paris')
        address = record.get('address', '')
        status = record.get('status', 'UNKNOWN')
        
        # Position GPS
        position = record.get('position', {})
        latitude = position.get('latitude', 0)
        longitude = position.get('longitude', 0)
        
        # Disponibilit√©s
        total_stands = record.get('totalStands', {})
        availabilities = total_stands.get('availabilities', {})
        capacity = total_stands.get('capacity', 0)
        
        bikes = availabilities.get('bikes', 0)
        stands = availabilities.get('stands', 0)
        mechanical_bikes = availabilities.get('mechanicalBikes', 0)
        electrical_bikes = availabilities.get('electricalBikes', 0)
        
        # Informations suppl√©mentaires
        banking = record.get('banking', False)
        bonus = record.get('bonus', False)
        connected = record.get('connected', True)
        overflow = record.get('overflow', False)
        last_update = record.get('lastUpdate', '')
        
        transformed = {
            'stationCode': str(number),
            'name': name,
            'contractName': contract,
            'address': address,
            'capacity': int(capacity),
            'numBikesAvailable': int(bikes),
            'numDocksAvailable': int(stands),
            'numMechanicalBikes': int(mechanical_bikes),
            'numElectricalBikes': int(electrical_bikes),
            'isInstalled': status == 'OPEN',
            'isReturning': status == 'OPEN',
            'isRenting': status == 'OPEN',
            'status': status,
            'coordinates': [float(longitude), float(latitude)],
            'latitude': float(latitude),
            'longitude': float(longitude),
            'banking': banking,
            'bonus': bonus,
            'connected': connected,
            'overflow': overflow,
            'timestamp': datetime.now().isoformat(),
            'lastUpdate': last_update
        }
        
        return transformed
        
    except Exception as e:
        print(f"‚ùå Error transforming record: {e}")
        print(f"Record: {record}")
        return None


def write_to_mongodb(batch_df, batch_id):
    """
    √âcrire un batch de donn√©es dans MongoDB
    Utilise upsert pour √©viter les doublons
    """
    try:
        records = batch_df.collect()
        
        if not records:
            print(f"‚ö†Ô∏è Batch {batch_id} is empty, skipping...")
            return
        
        # Connexion MongoDB
        client = MongoClient(MONGODB_URI)
        db = client[MONGODB_DB]
        collection = db[MONGODB_COLLECTION]
        
        # Convertir en documents
        documents = [row.asDict() for row in records]
        
        # Upsert bas√© sur stationCode pour √©viter les doublons
        updated_count = 0
        inserted_count = 0
        
        for doc in documents:
            result = collection.update_one(
                {'stationCode': doc['stationCode']},
                {'$set': doc},
                upsert=True
            )
            
            if result.upserted_id:
                inserted_count += 1
            elif result.modified_count > 0:
                updated_count += 1
        
        print(f"‚úÖ Batch {batch_id}: {inserted_count} inserted, {updated_count} updated in MongoDB")
        
        client.close()
        
    except Exception as e:
        print(f"‚ùå Error writing batch {batch_id} to MongoDB: {e}")


def write_to_hdfs(spark, batch_df, batch_id):
    """
    Archiver les donn√©es dans HDFS (optionnel)
    Organis√© par date: /velib/raw/YYYY-MM-DD/batch_XXX.json
    """
    if not HDFS_ENABLED:
        return
    
    try:
        current_date = datetime.now().strftime('%Y-%m-%d')
        hdfs_path = f"{HDFS_BASE_PATH}{current_date}/batch_{batch_id}.json"
        
        print(f"üíæ Archiving to HDFS: {hdfs_path}")
        
        batch_df.write \
            .mode("overwrite") \
            .format("json") \
            .save(hdfs_path)
        
        print(f"‚úÖ Batch {batch_id} archived to HDFS")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error writing to HDFS: {e}")
        print("   (Continuing without HDFS archiving)")


def run_streaming_pipeline(spark):
    """
    Pipeline principal de streaming
    R√©cup√®re les donn√©es toutes les 30 secondes et les stocke dans MongoDB + HDFS
    """
    print("=" * 70)
    print("üöÄ Starting V√©lib Streaming Pipeline (JCDecaux API)")
    print("=" * 70)
    
    batch_counter = 0
    
    while True:
        try:
            print(f"\n{'='*70}")
            print(f"üìä Processing batch #{batch_counter} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"{'='*70}")
            
            # 1. R√©cup√©rer les donn√©es de l'API
            records = fetch_velib_data()
            
            if not records:
                print("‚ö†Ô∏è No data fetched, waiting 30 seconds before retry...")
                time.sleep(30)
                continue
            
            # 2. Transformer les donn√©es
            print(f"üîÑ Transforming {len(records)} records...")
            transformed_records = [transform_jcdecaux_record(r) for r in records]
            transformed_records = [r for r in transformed_records if r is not None]
            
            print(f"‚úÖ Transformed {len(transformed_records)} valid records")
            
            # 3. Cr√©er un DataFrame Spark
            if transformed_records:
                df = spark.createDataFrame(transformed_records)
                
                # Afficher le sch√©ma (premi√®re fois seulement)
                if batch_counter == 0:
                    print("\nüìã DataFrame Schema:")
                    df.printSchema()
                    print("\nüìä Sample Data:")
                    df.show(5, truncate=False)
                
                # 4. √âcrire dans MongoDB
                write_to_mongodb(df, batch_counter)
                
                # 5. Archiver dans HDFS (optionnel)
                if HDFS_ENABLED:
                    write_to_hdfs(spark, df, batch_counter)
                
                # Statistiques du batch
                print(f"\nüìà Batch Statistics:")
                print(f"   - Total stations: {df.count()}")
                print(f"   - Bikes available: {df.agg({'numBikesAvailable': 'sum'}).collect()[0][0]}")
                print(f"   - Docks available: {df.agg({'numDocksAvailable': 'sum'}).collect()[0][0]}")
            
            batch_counter += 1
            
            # 6. Attendre avant le prochain batch
            print(f"\n‚è≥ Waiting 30 seconds before next batch...")
            time.sleep(30)
            
        except KeyboardInterrupt:
            print("\n" + "="*70)
            print("‚ö†Ô∏è Streaming pipeline interrupted by user")
            print("="*70)
            break
        except Exception as e:
            print(f"‚ùå Error in streaming pipeline: {e}")
            import traceback
            traceback.print_exc()
            print("‚è≥ Waiting 10 seconds before retry...")
            time.sleep(10)
    
    print("\nüõë Streaming pipeline stopped")


def main():
    """
    Point d'entr√©e principal
    """
    print("\n" + "=" * 70)
    print("üö¥ V√âLIB REAL-TIME STREAMING PIPELINE")
    print("   Data Source: JCDecaux API")
    print("=" * 70)
    
    # V√©rifier la cl√© API
    if JCDECAUX_API_KEY == 'YOUR_API_KEY_HERE':
        print("\n‚ö†Ô∏è  ATTENTION: Cl√© API manquante!")
        print("="*70)
        print("Pour utiliser ce pipeline, vous devez:")
        print("1. Obtenir une cl√© API gratuite sur:")
        print("   üëâ https://developer.jcdecaux.com/#/opendata/vls?page=getstarted")
        print("2. D√©finir la variable d'environnement:")
        print("   export JCDECAUX_API_KEY='votre_cle_api'")
        print("   OU")
        print("   Modifier JCDECAUX_API_KEY dans le fichier streaming-velib.py")
        print("="*70)
        return
    
    print(f"üîë API Key: {JCDECAUX_API_KEY[:10]}...")
    
    # Initialiser Spark
    spark = initialize_spark()
    
    try:
        # Lancer le pipeline de streaming
        run_streaming_pipeline(spark)
    except Exception as e:
        print(f"‚ùå Fatal error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # Arr√™ter Spark
        spark.stop()
        print("\n‚úÖ Spark session stopped")
        print("üëã Goodbye!")


if __name__ == "__main__":
    main()
```
