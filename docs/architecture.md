# ğŸ—ï¸ Architecture du Projet VÃ©lib Temps RÃ©el

## Vue d'ensemble

Ce projet implÃ©mente un pipeline Big Data temps rÃ©el ET batch pour le suivi des stations VÃ©lib Ã  Paris.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API VÃ©lib     â”‚  (Source de donnÃ©es en temps rÃ©el)
â”‚   Open Data     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           DOCKER                   â”‚
    â”‚                                    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚        HDFS              â”‚    â”‚
    â”‚  â”‚  (DonnÃ©es brutes)        â”‚â—„â”€â”€â”€â”¼â”€â”€â”€ DonnÃ©es brutes
    â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚       â”‚              â”‚            â”‚
    â”‚       â–¼              â–¼            â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
    â”‚  â”‚ Batch   â”‚   â”‚ Streaming â”‚     â”‚
    â”‚  â”‚ Spark   â”‚   â”‚  Spark    â”‚     â”‚
    â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚
    â”‚       â”‚              â”‚            â”‚
    â”‚       â–¼              â–¼            â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚       MongoDB            â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Backend API    â”‚
         â”‚  (Node.js)       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Frontend      â”‚
         â”‚   (React)        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Power BI      â”‚  (Optionnel)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Composants du SystÃ¨me

### 1. **Source de DonnÃ©es : API VÃ©lib**
- **URL** : `https://opendata.paris.fr/api/records/1.0/search/?dataset=velib-disponibilite-en-temps-reel`
- **Format** : JSON
- **FrÃ©quence** : DonnÃ©es mises Ã  jour en temps rÃ©el
- **Contenu** : DisponibilitÃ© des vÃ©los et places pour chaque station

### 2. **HDFS (Hadoop Distributed File System)**
- **RÃ´le** : Stockage des donnÃ©es brutes
- **Composants** :
  - **NameNode** (port 9870) - Gestion des mÃ©tadonnÃ©es
  - **DataNode** (port 9864) - Stockage physique
- **Structure** :
  - `/velib/raw/` - DonnÃ©es brutes de l'API
  - `/velib/processed/` - DonnÃ©es transformÃ©es par Batch

### 3. **Streaming : Apache Spark Structured Streaming**
- **RÃ´le** : Ingestion et transformation en temps rÃ©el
- **Technologie** : PySpark
- **FonctionnalitÃ©s** :
  - RÃ©cupÃ©ration de l'API VÃ©lib toutes les 30 secondes
  - Transformation et nettoyage des donnÃ©es JSON
  - Ã‰criture dans MongoDB via `foreachBatch`
  - Optionnel : Sauvegarde dans HDFS pour archivage

### 4. **Batch : Apache Spark Batch Processing**
- **RÃ´le** : Traitement et agrÃ©gation des donnÃ©es historiques
- **FonctionnalitÃ©s** :
  - Lecture des donnÃ©es brutes depuis HDFS
  - AgrÃ©gations quotidiennes (moyennes, min, max)
  - Analyse des patterns horaires
  - DÃ©tection d'anomalies
  - Statistiques globales
- **Sorties** :
  - HDFS (format Parquet) - DonnÃ©es transformÃ©es
  - MongoDB - RÃ©sultats agrÃ©gÃ©s pour le reporting

### 5. **Stockage : MongoDB**
- **Type** : Base de donnÃ©es NoSQL orientÃ©e documents
- **Collections** :
  - `stations` - DonnÃ©es temps rÃ©el (streaming)
  - `stations_aggregated` - DonnÃ©es agrÃ©gÃ©es (batch)
  - `daily_stats` - Statistiques quotidiennes (batch)
- **Index** :
  - `stationCode` (unique)
  - `timestamp` (pour les requÃªtes temporelles)
  - `name` (recherche full-text)

### 6. **Backend : Node.js + Express**
- **RÃ´le** : API REST pour exposer les donnÃ©es
- **Endpoints** :
  - `GET /api/stations` - Liste toutes les stations (avec pagination)
  - `GET /api/stations/top` - Stations avec le plus de vÃ©los
  - `GET /api/stations/critical` - Stations critiques
  - `GET /api/stations/:id` - DÃ©tails d'une station
  - `GET /api/stats` - Statistiques globales
- **Port** : 3000

### 7. **Frontend : React + Vite**
- **RÃ´le** : Interface utilisateur temps rÃ©el
- **Composants** :
  - `RealtimeDashboard` - Statistiques globales
  - `StationTable` - Tableau avec filtres et tri
- **BibliothÃ¨ques** :
  - React Leaflet (cartes) - TODO
  - Recharts (graphiques) - TODO
  - Axios (requÃªtes HTTP)
- **Port** : 5173

### 8. **Power BI** (Optionnel)
- **RÃ´le** : Visualisation avancÃ©e et reporting
- **Source** : MongoDB (connexion directe)
- **Dashboards** : Analyse des tendances historiques

---

## ğŸ³ Infrastructure Docker

### Services Docker Compose

```yaml
- mongo:27017          # MongoDB
- namenode:9870        # HDFS NameNode UI
- namenode:9000        # HDFS NameNode API
- datanode:9864        # HDFS DataNode
- spark-master:8080    # Spark Master UI
- spark-master:7077    # Spark Master
- spark-worker         # Spark Worker
- backend:3000         # API Node.js
```

### RÃ©seau
Tous les services partagent le rÃ©seau `velib_network` pour communiquer entre eux.

### Volumes
- `mongo_data` - Persistance MongoDB
- `spark_data` - DonnÃ©es temporaires Spark
- `namenode_data` - MÃ©tadonnÃ©es HDFS
- `datanode_data` - DonnÃ©es HDFS

---

## ğŸ”„ Flux de DonnÃ©es

### Pipeline Temps RÃ©el (Streaming)

1. **Ingestion** (toutes les 30s)
   ```
   API VÃ©lib â†’ Spark Streaming â†’ Transformation
   ```

2. **Stockage**
   ```
   Spark â†’ MongoDB (upsert) + HDFS (optionnel)
   ```

3. **Exposition**
   ```
   MongoDB â†’ Backend API â†’ Frontend React
   ```

### Pipeline Batch (Traitement quotidien)

1. **Lecture**
   ```
   HDFS (donnÃ©es brutes) â†’ Spark Batch
   ```

2. **Transformation**
   ```
   Spark Batch â†’ AgrÃ©gations + Nettoyage + Analyse
   ```

3. **Ã‰criture**
   ```
   Spark â†’ HDFS (Parquet) + MongoDB (rÃ©sultats)
   ```

4. **Visualisation**
   ```
   MongoDB â†’ Power BI / Frontend
   ```

---

## ğŸ“Š SchÃ©ma de DonnÃ©es

### Collection MongoDB : `stations` (Temps RÃ©el)

```json
{
  "_id": ObjectId("..."),
  "stationCode": "16107",
  "name": "Benjamin Godard - Victor Hugo",
  "capacity": 35,
  "numBikesAvailable": 12,
  "numDocksAvailable": 23,
  "isInstalled": true,
  "isReturning": true,
  "isRenting": true,
  "coordinates": [2.275725, 48.865983],
  "timestamp": "2024-01-15T14:30:00.000Z",
  "lastUpdate": "2024-01-15T14:29:45.000Z"
}
```

### Collection MongoDB : `stations_aggregated` (Batch)

```json
{
  "stationCode": "16107",
  "name": "Benjamin Godard - Victor Hugo",
  "date": "2024-01-15",
  "avgBikesAvailable": 15.3,
  "minBikesAvailable": 2,
  "maxBikesAvailable": 28,
  "avgDocksAvailable": 19.7,
  "recordCount": 2880
}
```

---

## ğŸš€ Ã‰volutions Futures

### Phase 1 (Actuelle)
- [x] Pipeline streaming fonctionnel
- [x] Pipeline batch fonctionnel
- [x] HDFS intÃ©grÃ©
- [x] Backend API REST
- [x] Frontend avec statistiques
- [ ] Tests et validation

### Phase 2 (Prochaine)
- [ ] Carte interactive avec React Leaflet
- [ ] Graphiques temps rÃ©el avec Recharts
- [ ] WebSocket pour push temps rÃ©el
- [ ] Dashboards Power BI
- [ ] Notifications pour stations critiques

### Phase 3 (Future)
- [ ] Machine Learning (prÃ©diction de disponibilitÃ©)
- [ ] Historisation avancÃ©e (Time Series)
- [ ] Analytics avancÃ©s (patterns d'utilisation)
- [ ] API GraphQL
- [ ] Optimisation avec Apache Kafka

---

## ğŸ”§ Technologies UtilisÃ©es

| Couche | Technologie | Version |
|--------|-------------|---------|
| Stockage distribuÃ© | HDFS (Hadoop) | 3.2.1 |
| Streaming | Apache Spark | 3.5.0 |
| Batch | Apache Spark | 3.5.0 |
| Base de donnÃ©es | MongoDB | Latest |
| Backend | Node.js + Express | 18.x |
| Frontend | React + Vite | 18.x |
| Conteneurisation | Docker Compose | 3.8 |
| Langages | Python, JavaScript | 3.x, ES6+ |

---

## ğŸ“ˆ MÃ©triques et Monitoring

### KPIs Ã  suivre
- Latence d'ingestion (API â†’ MongoDB)
- DÃ©bit de traitement (records/seconde)
- Utilisation HDFS (espace disque)
- Performance Spark (jobs batch)
- DisponibilitÃ© du systÃ¨me
- Temps de rÃ©ponse API REST

### TODO : Ajouter
- Prometheus pour les mÃ©triques
- Grafana pour les dashboards
- Alerting sur incidents

---

## ğŸ” SÃ©curitÃ©

### Actuel
- Authentification MongoDB (admin/password)
- CORS configurÃ© sur le backend
- Helmet.js pour sÃ©curitÃ© HTTP

### TODO
- Authentification JWT pour l'API
- Kerberos pour HDFS
- Rate limiting
- HTTPS/SSL
- Variables d'environnement sÃ©curisÃ©es

---

## ğŸ¯ DiffÃ©rences Streaming vs Batch

| CritÃ¨re | Streaming | Batch |
|---------|-----------|-------|
| **FrÃ©quence** | Temps rÃ©el (30s) | Quotidien/Horaire |
| **Latence** | Faible (<1 min) | Haute (heures) |
| **Source** | API VÃ©lib | HDFS |
| **Cible** | MongoDB + HDFS | MongoDB + HDFS |
| **Use Case** | Monitoring temps rÃ©el | Analyse historique |
| **ComplexitÃ©** | Simple (upsert) | Complexe (agrÃ©gations) |

---

**Auteur** : Ã‰quipe Big Data  
**DerniÃ¨re mise Ã  jour** : 2024
