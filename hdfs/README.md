# ğŸ—‚ï¸ HDFS - Hadoop Distributed File System

Configuration et gestion de HDFS pour le projet VÃ©lib.

## ğŸ“¦ Architecture HDFS

```
HDFS Cluster
â”œâ”€â”€ NameNode (port 9870, 9000)
â”‚   â””â”€â”€ Gestion des mÃ©tadonnÃ©es
â””â”€â”€ DataNode (port 9864)
    â””â”€â”€ Stockage physique des donnÃ©es
```

## ğŸ“ Structure des Dossiers HDFS

```
/velib/
â”œâ”€â”€ raw/                          # DonnÃ©es brutes de l'API
â”‚   â””â”€â”€ YYYY-MM-DD/              # OrganisÃ© par date
â”‚       â””â”€â”€ batch_*.json
â”œâ”€â”€ processed/                    # DonnÃ©es traitÃ©es par Batch
â”‚   â”œâ”€â”€ daily_stats/             # Stats quotidiennes (Parquet)
â”‚   â”œâ”€â”€ hourly_patterns/         # Patterns horaires (Parquet)
â”‚   â””â”€â”€ anomalies/               # DÃ©tections d'anomalies (Parquet)
```

## ğŸš€ DÃ©marrage

### 1. DÃ©marrer les services HDFS

```bash
cd docker
docker-compose up namenode datanode -d
```

### 2. VÃ©rifier le statut

```bash
# VÃ©rifier les conteneurs
docker ps | grep velib

# AccÃ©der Ã  l'interface web NameNode
# http://localhost:9870
```

### 3. Initialiser la structure HDFS

```bash
# Sous Linux/Mac
cd docker
chmod +x hdfs-utils.sh
./hdfs-utils.sh init

# Sous Windows (Git Bash ou WSL)
bash hdfs-utils.sh init
```

## ğŸ› ï¸ Commandes Utiles

### Avec le script hdfs-utils.sh

```bash
# Lister tous les fichiers
./hdfs-utils.sh list

# Voir le statut du cluster
./hdfs-utils.sh status

# Voir l'utilisation disque
./hdfs-utils.sh usage

# Upload un fichier
./hdfs-utils.sh upload data.json /velib/raw/

# Download un fichier
./hdfs-utils.sh download /velib/raw/data.json ./

# Supprimer un fichier
./hdfs-utils.sh delete /velib/raw/old_data.json

# Nettoyer toutes les donnÃ©es
./hdfs-utils.sh clean
```

### Commandes HDFS Directes

```bash
# ExÃ©cuter des commandes HDFS dans le conteneur
docker exec velib_namenode hdfs dfs -ls /velib

# CrÃ©er un dossier
docker exec velib_namenode hdfs dfs -mkdir -p /velib/test

# Upload
docker exec velib_namenode hdfs dfs -put /local/file.txt /velib/

# Download
docker exec velib_namenode hdfs dfs -get /velib/file.txt /local/

# Lire un fichier
docker exec velib_namenode hdfs dfs -cat /velib/file.txt

# Supprimer
docker exec velib_namenode hdfs dfs -rm -r /velib/test

# Voir l'espace disque
docker exec velib_namenode hdfs dfs -df -h

# VÃ©rifier la santÃ© du cluster
docker exec velib_namenode hdfs dfsadmin -report
```

## ğŸ”§ Configuration

Les configurations HDFS sont dans `hadoop.env` :

- **Replication Factor** : 1 (pour dev, 3 pour prod)
- **Block Size** : 128 MB
- **NameNode Port** : 9000 (API), 9870 (Web UI)
- **DataNode Port** : 9864

## ğŸ“Š Monitoring

### Interface Web NameNode

- **URL** : http://localhost:9870
- **FonctionnalitÃ©s** :
  - Vue d'ensemble du cluster
  - Browse du systÃ¨me de fichiers
  - Logs et mÃ©triques
  - Informations sur les DataNodes

### Commandes de Monitoring

```bash
# Rapport complet du cluster
docker exec velib_namenode hdfs dfsadmin -report

# SantÃ© du NameNode
docker exec velib_namenode hdfs dfsadmin -safemode get

# Lister les fichiers corrompus
docker exec velib_namenode hdfs fsck / -files -blocks
```

## ğŸ”„ IntÃ©gration avec Spark

### Streaming â†’ HDFS

Le pipeline Streaming peut sauvegarder les donnÃ©es brutes dans HDFS :

```python
# Dans streaming-velib.py
df.write \
    .mode("append") \
    .format("json") \
    .save(f"hdfs://namenode:9000/velib/raw/{current_date}/")
```

### Batch â† HDFS

Le pipeline Batch lit depuis HDFS :

```python
# Dans batch-velib.py
df = spark.read.json("hdfs://namenode:9000/velib/raw/*/")
```

## ğŸ› DÃ©pannage

### NameNode ne dÃ©marre pas

```bash
# VÃ©rifier les logs
docker logs velib_namenode

# RÃ©initialiser le NameNode (ATTENTION: perd les donnÃ©es)
docker-compose down -v
docker-compose up namenode -d
```

### Espace disque plein

```bash
# VÃ©rifier l'utilisation
./hdfs-utils.sh usage

# Nettoyer les vieux fichiers
docker exec velib_namenode hdfs dfs -rm -r /velib/raw/2023-*
```

### ProblÃ¨me de permissions

```bash
# Changer les permissions
docker exec velib_namenode hdfs dfs -chmod -R 777 /velib
```

### DataNode ne se connecte pas au NameNode

```bash
# RedÃ©marrer le DataNode
docker-compose restart datanode

# VÃ©rifier les logs
docker logs velib_datanode
```

## ğŸ“ Bonnes Pratiques

1. **Organisation par date** : Stocker les donnÃ©es raw par date (YYYY-MM-DD)
2. **Format Parquet** : Utiliser Parquet pour les donnÃ©es processed (plus efficace)
3. **Compression** : Activer la compression (Snappy, Gzip)
4. **RÃ©tention** : Nettoyer les anciennes donnÃ©es rÃ©guliÃ¨rement
5. **Backup** : Sauvegarder les donnÃ©es critiques hors HDFS

## ğŸ” SÃ©curitÃ©

### Configuration Actuelle (Dev)

- Permissions dÃ©sactivÃ©es (`dfs.permissions.enabled=false`)
- Pas d'authentification Kerberos

### Pour Production

```bash
# Activer les permissions
HDFS_CONF_dfs_permissions_enabled=true

# Configurer Kerberos
# TODO: Ajouter la configuration Kerberos
```

## ğŸ“ˆ Performance

### Optimisations

1. **Augmenter les ressources DataNode**
   ```yaml
   # Dans docker-compose.yml
   datanode:
     deploy:
       resources:
         limits:
           memory: 4G
   ```

2. **Ajuster le block size** selon la taille des fichiers
3. **Augmenter le replication factor** en production (3)

## ğŸ†˜ Aide

Pour plus d'informations :

```bash
./hdfs-utils.sh help
```

---

**Note** : Cette configuration est optimisÃ©e pour le dÃ©veloppement. Pour la production, il faudra ajuster les paramÃ¨tres de sÃ©curitÃ© et de performance.
