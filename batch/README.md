# ğŸ“Š Batch Processing - Spark Batch

Ce module gÃ¨re le traitement batch des donnÃ©es brutes VÃ©lib stockÃ©es dans HDFS.

## ğŸ¯ Objectif

Le pipeline batch lit les donnÃ©es brutes depuis HDFS, effectue des transformations et agrÃ©gations complexes, puis Ã©crit les rÃ©sultats dans MongoDB pour l'analyse et le reporting.

## ğŸ“‚ Architecture

```
DonnÃ©es brutes (HDFS) 
    â†’ Spark Batch Processing 
    â†’ AgrÃ©gations & Transformations 
    â†’ HDFS (donnÃ©es transformÃ©es) + MongoDB (rÃ©sultats)
```

## ğŸ”§ FonctionnalitÃ©s

- **AgrÃ©gations quotidiennes** : Calcul des moyennes, min, max par station et par jour
- **Patterns horaires** : Analyse des tendances d'utilisation par heure
- **DÃ©tection d'anomalies** : Identification des stations avec comportements suspects
- **Statistiques globales** : MÃ©triques systÃ¨me (total stations, vÃ©los, places, etc.)

## ğŸš€ Utilisation

### ExÃ©cution locale

```bash
cd batch
python batch-velib.py
```

### ExÃ©cution avec Spark Submit

```bash
spark-submit --master spark://spark:7077 batch-velib.py
```

### Traiter une date spÃ©cifique

```bash
python batch-velib.py 2024-01-15
```

## ğŸ“Š Sorties

### HDFS
- `/velib/processed/daily_stats/` - Statistiques quotidiennes (Parquet)
- `/velib/processed/hourly_patterns/` - Patterns horaires (Parquet)
- `/velib/processed/anomalies/` - DÃ©tection d'anomalies (Parquet)

### MongoDB
- Collection `stations_aggregated` - DonnÃ©es agrÃ©gÃ©es
- Collection `daily_stats` - Statistiques quotidiennes

## ğŸ“ TODO

- [ ] Ajouter la prÃ©diction de disponibilitÃ© (ML)
- [ ] ImplÃ©menter le partitionnement par date
- [ ] Optimiser les performances avec cache
- [ ] Ajouter des tests unitaires
